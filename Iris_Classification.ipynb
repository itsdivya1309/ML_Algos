import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt
from subprocess import check_output
print(check_output(["ls", "../input"]).decode("utf8"))

iris = pd.read_csv("/kaggle/input/iris/Iris.csv")

iris.head()

iris.describe()   #description

iris.info()
# get ds info

iris.drop('Id', axis=1,inplace=True)

iris["Species"].value_counts()
# to get type of species we are working with

graph1 = iris[iris.Species=='Iris-setosa'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='blue', label='Setosa')
# graph for species setosa
graph1 = iris[iris.Species=='Iris-versicolor'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='green', label='Versicolor')
#  graph for species versicolor
graph1 = iris[iris.Species=='Iris-virginica'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='brown', label='Virginica')
# graph for species vriginica

# combined graph for species as sepal len vs sepal width
graph1 = iris[iris.Species=='Iris-setosa'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='blue', label='Setosa')
iris[iris.Species=='Iris-versicolor'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='green', label='Versicolor', ax = graph1)
iris[iris.Species=='Iris-virginica'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='brown', label='Virginica', ax = graph1)
# included ax = graph1 to include the other two species in same 
# graph as species one, i.e. graph1
graph1.set_xlabel("Sepal length")
graph1.set_ylabel("Sepal width")
graph1.set_title("Sepal Length VS Width")
graph1 = plt.gcf()
graph1.set_size_inches(12,6)
plt.show()

# we can also make similar plot using seaborn
sns.jointplot(x='SepalLengthCm', y='SepalWidthCm', data=iris, size=5)

# to differentiat btw species we 
sns.FacetGrid(iris, hue="Species").map(plt.scatter, "SepalLengthCm", "SepalWidthCm").add_legend()

# graph for petal length and width
graph1 = iris[iris.Species=='Iris-setosa'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='blue', label='Setosa')
# graph for species setosa
graph1 = iris[iris.Species=='Iris-versicolor'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='green', label='Versicolor')
#  graph for species versicolor
graph1 = iris[iris.Species=='Iris-virginica'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='brown', label='Virginica')
# graph for species vriginica

#combined graph for petal len and width
graph1 = iris[iris.Species=='Iris-setosa'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='blue', label='Setosa')
iris[iris.Species=='Iris-versicolor'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='green', label='Versicolor', ax = graph1)
iris[iris.Species=='Iris-virginica'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='brown', label='Virginica', ax = graph1)
# included ax = graph1 to include the other two species in same 
# graph as species one, i.e. graph1
graph1.set_xlabel("Petal length")
graph1.set_ylabel("Petal width")
graph1.set_title("Petal Length VS Width")
graph1 = plt.gcf()
graph1.set_size_inches(12,6)
plt.show()

# length and width distribution
iris.hist(edgecolor = 'black', color = 'red', linewidth=1.2)
# color used to change bar color
graph1=plt.gcf()
graph1.set_size_inches(12,6)
plt.show()

# length and width varing according to species
# we will use seaborn's stripplot on boxplot plot with jitter=True, so points don't fall single line
plt.figure(figsize=(16,8))
plt.subplot(2,2,1)
graph2 = sns.boxplot(x="Species", y= "PetalLengthCm", data = iris)
graph2 = sns.stripplot(x="Species", y= "PetalLengthCm", data = iris, jitter= True, edgecolor="black")
plt.subplot(2,2,2)
graph2 = sns.boxplot(x="Species", y= "SepalLengthCm", data = iris)
graph2 = sns.stripplot(x="Species", y= "SepalLengthCm", data = iris, jitter= True, edgecolor="black")
plt.subplot(2,2,3)
graph2 = sns.boxplot(x="Species", y= "PetalWidthCm", data = iris)
graph2 = sns.stripplot(x="Species", y= "PetalWidthCm", data = iris, jitter= True, edgecolor="black")
plt.subplot(2,2,4)
graph2 = sns.boxplot(x="Species", y= "SepalWidthCm", data = iris)
graph2 = sns.stripplot(x="Species", y= "SepalWidthCm", data = iris, jitter= True, edgecolor="black")

# will use violin plot as it combines above two plots into a single plot
# denser regions fatter, sparse regions thin
plt.figure(figsize=(15,10))
plt.subplot(2,2,1)
sns.violinplot(x="Species", y="PetalLengthCm", data=iris)
plt.subplot(2,2,2)
sns.violinplot(x="Species", y="PetalWidthCm", data=iris)
plt.subplot(2,2,3)
sns.violinplot(x="Species", y="SepalLengthCm", data=iris)
plt.subplot(2,2,4)
sns.violinplot(x="Species", y="SepalWidthCm", data=iris)

# kde plot: a method for visualizing the distribution of observations 
# in a dataset, analogous to a histogram
# a last plot of sns to univariate above relations in KDEplot 

# kdeplot of petal length
sns.FacetGrid(iris, hue="Species") .map(sns.kdeplot, "PetalLengthCm") .add_legend()

# kdeplot of sepal length
sns.FacetGrid(iris, hue="Species") .map(sns.kdeplot, "SepalLengthCm") .add_legend()

# kdeplot of sepal width
sns.FacetGrid(iris, hue="Species") .map(sns.kdeplot, "SepalWidthCm") .add_legend()

# kdeplot of petal width
sns.FacetGrid(iris, hue="Species") .map(sns.kdeplot, "PetalWidthCm") .add_legend()

# another plot is pairplot shows bivariate btw each pair of features
# comes with histo but we put kdeplot here

sns.pairplot(iris, hue = "Species", size=3, diag_kind="kde")

# Classification Model 

# classification: model tries to predict the correct label of a given input data.
# regression: a technique that predicts outcomes by capturing relationships between independent and dependent variables.
#      or//   mathematical methods that allow data scientists to predict a continuous outcome (y) based on the value of one or more predictor variables (x).
# import all important classification packages
from sklearn.linear_model import LogisticRegression  # logistic reg algo
from sklearn.model_selection import train_test_split  # split ds for training and testing
from sklearn.neighbors import KNeighborsClassifier  # K nearest neighbor
from sklearn import svm  # Support Vector Machines algo
from sklearn import metrics  # check model accuracy
from sklearn.tree import DecisionTreeClassifier  # Decision Tree algo
iris.shape  # to get shape of ds

# no. of features and their correlation is imp
# many correlated features will reduce the accuracy 
iris.drop('Species', axis=1,inplace=True)
print(iris)

# draw heatmap  
# input is correlation matrix calculted by matrix
matrix = iris.corr()
print(matrix)

plt.figure(figsize=(8,4))
sns.heatmap(matrix, annot=True, cmap='cubehelix_r')
# annot parameter only allows the addition of numeric values to a python heatmap cell
plt.show()

# we use i sepal and 1 petal feature which are not highly correlated
# split the data into training and testing set before passing training into algo
train, test = train_test_split(iris, test_size=0.3)
# splits data as 70% train and 30% test
print(train.shape)
print(test.shape)

iris = pd.read_csv("/kaggle/input/iris/Iris.csv")
iris["Species"]

iris

x=iris.iloc[:,:-1]
y=iris.iloc[:,4]
x_train,x_test, y_train, y_test=train_test_split(x,y,test_size=0.3)

# svm
from sklearn.svm import SVC
model=SVC()

model.fit(x_train, y_train)

pred=model.predict(x_test)
print('The accuracy of the SVM is:',metrics.accuracy_score(pred,y_test))

# checking accuracy with logistic regression
model = LogisticRegression()
model.fit(x_train, y_train)
pred = model.predict(x_test)
print('The accuracy of Logistic Regression: ', metrics.accuracy_score(pred, y_test))

# checking accuracy with Decision Tree
model = DecisionTreeClassifier()
model.fit(x_train, y_train)
pred = model.predict(x_test)
print('Accuracy of Decision Tree: ', metrics.accuracy_score(pred, y_test))

# accuracy with KNeighbors
model = KNeighborsClassifier(n_neighbors=3)
model.fit(x_train, y_train)
pred = model.predict(x_test)
print('Accuracy of KNN: ', metrics.accuracy_score(pred, y_test))

** the end **
